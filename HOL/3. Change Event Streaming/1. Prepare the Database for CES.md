# Prepare the Database for CES

To get started, let's configure a database. We'll enable the database for Change Event Streaming (CES), create a stream group, and define stored procedures to simulate transactional activity.

You're welcome! Here's a clear and concise explanation tailored for your lab attendees:

## Shared Lab Resources and the Need for Isolation

In this lab, all **attendees will be working concurrently** with a **shared Azure Event Hubs namespace** and a **shared Azure Blob Storage container** for checkpointing. This approach conserves resources and simplifies setup, but does introduces a few important concerns:

- **Event Stream Overlap**

   Without proper isolation, events generated by one attendee will be seen by all other attendees. This would break the integrity of individual lab results and lead to confusion.

- **Checkpoint Collision**

   Azure Event Hubs uses **consumer groups** and **blob storage checkpoints** to track progress. If two attendees share the same consumer group or storage path, their progress can overwrite each other’s, causing data loss or duplication.

To ensure that each attendee sees only their own events and progress, we implement the following strategies:

- **Unique Database Name per Attendee**

   Each attendee will use different name for their database, based on their first and last names (for example, `CesDemo_john_smith`, and `CesDemo_jane_doe`).

   > This allows filtering on database name in the client application to ensure that you only process changes that are made in your database.

- **Unique Event Hub Consumer Group Name per Attendee**

   Similarly, each attendee will be assigned a unique Event Hub consumer group (for example, `cg-john-smith`, `cg-jane-doe`).

   > All checkpoint data is stored in the same Azure Blob Storage container, but because each consumer group is unique, each attendee has their own isolated set of checkpoint blobs, ensuring you receive your own event stream without interference from other attendees.

## Create and Configure the Database

Run the following T-SQL to create and use a new database for this lab. Be sure to suffix the database name with your first and last name to ensure isolation from other attendees sharing the same Event Hub and Blob Storage container (e.g., `CesDemo_john_smith`).

> **Note:** Use underscore `_` characters (not dashes `-`) for delimiters in the database name.

```sql
USE master
GO

CREATE DATABASE CesDemo_firstname_lastname
GO

USE CesDemo_firstname_lastname
GO
```

### Create the Database Master Key

You must create a database master key to securely store the credential to access the Azure Event Hub resource for this lab. This key is encrypted by a password. Only one master key is needed and permitted per database, so if it already exists from a previous lab, this command will not recreate it.

```sql
IF NOT EXISTS (SELECT * FROM sys.symmetric_keys WHERE name = '##MS_DatabaseMasterKey##')
    CREATE MASTER KEY ENCRYPTION BY PASSWORD = 'H@rd2Gue$$P@$$w0rd'
```

### Create the Credential Used by CES

This credential holds the SAS token enabling access to the Event Hub that SQL Server will stream events to as data changes in the database. Replace the placeholder with the token provided by your instructor.

```sql
CREATE DATABASE SCOPED CREDENTIAL SqlCesCredential
WITH
    IDENTITY = 'SHARED ACCESS SIGNATURE',
    SECRET = '<provided by instructor>'
```

### Enable CES

Run the following query to verify that (at this stage) CES is currently not enabled on any databases:

```sql
SELECT * FROM sys.databases WHERE is_event_stream_enabled = 1
```

Now run this statement to enable CES for the current database. This allows SQL Server to start capturing change events for selected tables in the database.

```sql
EXEC sys.sp_enable_event_stream
```

Now re-run the previous query to confirm CES is enabled for the current database (CesDemo):

```sql
SELECT * FROM sys.databases WHERE is_event_stream_enabled = 1
```

### Create the Event Stream Group

Now let's create the stream group. This is a SQL Server concept that allows you to group multiple tables together for change event streaming. The group will be configured to send events to an specific Azure Event Hub.

> **IMPORTANT:** SQL Server *stream groups* should not to be confused with Event Hub *consumer groups*. As explained, the latter allows multiple consumers to share the same Azure Blob Storage container while maintaining checkpoint isolation.

```sql
EXEC sys.sp_create_event_stream_group
  @stream_group_name      = 'SqlCesGroup',
  @destination_location   = 'sql2025-ces.servicebus.windows.net/ces-hub',
  @destination_credential = SqlCesCredential,
  @destination_type       = 'AzureEventHubsAmqp'
```

In this code:

- **@stream_group_name:** Creates an event stream group named `SqlCesGroup`

- **@destination_location:** Tells SQL Server to send change events to the Azure Event Hub at `sql2025-ces.servicebus.windows.net/ces-hub`.
  > This syntax describes an Event Hub named `ces-hub`, which exists in an Event Hub namespace named `sql2025-ces`.

- **@destination_credential:** The credential `SqlCesCredential` provides the necessary access permissions to the Event Hub, which you've already configured with the approprate SAS token.

- **@destination_type:** This parameter specifies that the events will be sent using the AMQP protocol, which is the standard for Azure Event Hubs.
  > AMQP stands for Advanced Message Queuing Protocol, a protocol used for message-oriented middleware that allows for efficient and reliable message delivery.

## Create the Tables

We'll create a few tables to model a basic order processing system.

First create the `Customer` table and populate it with two customers:

```sql
CREATE TABLE Customer (
  CustomerId    int IDENTITY PRIMARY KEY,
  CustomerName  varchar(50),
  City          varchar(20)
)
GO

SET IDENTITY_INSERT Customer ON
INSERT INTO Customer
  (CustomerId,  CustomerName,               City) VALUES
  (1,           'Shutter Bros Wholesale',   'New York'),
  (2,           'Aperture Supply Co.',      'Los Angeles')
SET IDENTITY_INSERT Customer OFF
GO
```

Next, create and populate the `Product` table with a catalog of products:

```sql
CREATE TABLE Product (
  ProductId     int IDENTITY PRIMARY KEY,
  Name          varchar(80),
  Color         varchar(15),
  Category      varchar(20),
  UnitPrice     decimal(8, 2),
  ItemsInStock  smallint
)
GO

SET IDENTITY_INSERT Product ON
INSERT INTO Product
  (ProductId,   Name,                                   Color,      Category,       UnitPrice,  ItemsInStock) VALUES 
  (1,           'Canon EOS R5 Mirrorless Camera',       'Black',    'Camera',       3899.99,    10),
  (2,           'Nikon Z6 II Mirrorless Camera',        'Silver',   'Camera',       1996.95,    8),
  (3,           'Sony NP-FZ100 Rechargeable Battery',   'Black',    'Accessory',    78.00,      25)
SET IDENTITY_INSERT Product OFF
GO
```

Finally, create the `Order` and `OrderDetail` tables. We'll populate them later with sample order data.

```sql
CREATE TABLE [Order] (
  OrderId       int IDENTITY PRIMARY KEY,
  CustomerId    int REFERENCES Customer(CustomerId),
  OrderDate     datetime2
)
GO

CREATE TABLE OrderDetail (
  OrderDetailId int IDENTITY PRIMARY KEY,
  OrderId       int REFERENCES [Order](OrderId),
  ProductId     int REFERENCES Product(ProductId),
  Quantity      smallint
)
GO
```

Finally, create and populate `TableWithNoPK`. This table will be used to demonstrate how CES behaves when a table lacks a primary key and does not include all columns.

```sql
CREATE TABLE TableWithNoPK (    -- This table lacks Primary Key. Combining that with IncludeAllColumns = 0 is a challenge...
  Id        int IDENTITY,
  Datacol   varchar(50)
)
GO

INSERT INTO TableWithNoPK (Datacol) VALUES
  ('Blue'),
  ('Car'),
  ('Fast'),
  ('Hello hey')
GO
```

## Create a Trigger

This trigger ensures product stock levels are automatically updated when order lines are added, changed, or deleted. The purpose of this trigger is to demonstrate that Change Event Streaming can capture the "side-effect" on data changes resulting from triggers.

```sql
CREATE TRIGGER trgUpdateItemsInStock ON OrderDetail AFTER INSERT, UPDATE, DELETE
AS
BEGIN
  -- Handle insert
  IF EXISTS (SELECT * FROM inserted) AND NOT EXISTS (SELECT * FROM deleted)
    UPDATE Product
    SET ItemsInStock = p.ItemsInStock - i.Quantity
    FROM
      Product AS p
      INNER JOIN inserted AS i ON p.ProductId = i.ProductId

  -- Handle update
  ELSE IF EXISTS (SELECT * FROM inserted) AND EXISTS (SELECT * FROM deleted) AND UPDATE(Quantity)
    UPDATE Product
    SET ItemsInStock = p.ItemsInStock + d.Quantity - i.Quantity
    FROM
      Product AS p
      INNER JOIN inserted AS i ON p.ProductId = i.ProductId
      INNER JOIN deleted AS d ON p.ProductId = d.ProductId

  -- Handle delete
  ELSE IF EXISTS (SELECT * FROM deleted) AND NOT EXISTS (SELECT * FROM inserted)
    UPDATE Product
    SET ItemsInStock = p.ItemsInStock + d.Quantity
    FROM
      Product AS p
      INNER JOIN deleted AS d ON p.ProductId = d.ProductId
END
GO
```

With this trigger in place, any changes to the OrderDetail table will automatically adjust the stock levels in the Product table. This is a common pattern in order management systems to ensure inventory levels are always accurate. As a result, events for products affected by order detail changes will also be generated, demonstrating how CES captures cascading changes across related tables that leverage DML triggers.

## Create the Stored Procedures

Now create the following stored procedures:

```sql
CREATE OR ALTER PROC CreateOrder
  @CustomerId int
AS
BEGIN
  INSERT INTO [Order](CustomerId, OrderDate)
  VALUES (@CustomerId, SYSDATETIME())

  SELECT OrderId = SCOPE_IDENTITY()
END
GO

CREATE OR ALTER PROC CreateOrderDetail
  @OrderId int,
  @ProductId int,
  @Quantity smallint
AS
BEGIN
  INSERT INTO OrderDetail (OrderId, ProductId, Quantity)
  VALUES (@OrderId, @ProductId, @Quantity)

  SELECT OrderDetailId = SCOPE_IDENTITY()
END
GO

CREATE OR ALTER PROC DeleteOrder
  @OrderId int
AS
BEGIN
  BEGIN TRANSACTION
    DELETE FROM OrderDetail WHERE OrderId = @OrderId
    DELETE FROM [Order] WHERE OrderId = @OrderId
  COMMIT TRANSACTION
END
GO
```

Each stored procedure represents a key business operation:

- **CreateOrder**: Inserts a new order for a specified customer.

- **CreateOrderDetail**: Adds a line item to an existing order, specifying the product and quantity. In turn, this triggers an update to the `Product` table to adjust stock levels.

- **DeleteOrder**: Deletes an order and all its associated order details in a single transaction, ensuring data integrity. In turn, this will also trigger updates to the `Product` table to restore stock levels for any products that were part of the deleted order details.

## Add Tables to the Stream Group

To capture change events for specific tables, you need to add them to the stream group you created earlier. This tells SQL Server which tables to monitor for changes and how to handle those changes in terms of event payloads.

Link each table to the stream group and configure how much data CES includes in the event payload. Two key options control this:

* `@include_old_values`: When set to 1, CES includes the *previous* values of each column for UPDATE and DELETE operations. Use this when you want to compare old vs. new values.

* `@include_all_columns`: When set to 1, CES includes *all* columns of the row even if only one column changes. When set to 0, only primary key and changed columns are included.

In this lab:

* `Product`, `Order`, and `OrderLine` include old values to detect stock changes or order modifications.
* `Customer` does not include old values but does include all columns, which is useful for simpler data monitoring.
* `TableWithNoPK` includes neither old values nor all columns. This highlights the limitations of tracking change events on poorly defined schemas.

> Be sure to reference the same stream group name you created earlier, appending your first and last name to ensure uniqueness.

```sql
EXEC sys.sp_add_object_to_event_stream_group
  @stream_group_name = 'SqlCesGroup',
  @object_name = 'dbo.Customer',
  @include_old_values = 0,
  @include_all_columns = 1

EXEC sys.sp_add_object_to_event_stream_group
  @stream_group_name = 'SqlCesGroup',
  @object_name = 'dbo.Product',
  @include_old_values = 1,
  @include_all_columns = 0

EXEC sys.sp_add_object_to_event_stream_group
  @stream_group_name = 'SqlCesGroup',
  @object_name = 'dbo.Order',
  @include_old_values = 1,
  @include_all_columns = 0

EXEC sys.sp_add_object_to_event_stream_group
  @stream_group_name = 'SqlCesGroup',
  @object_name = 'dbo.OrderDetail',
  @include_old_values = 1,
  @include_all_columns = 0

EXEC sys.sp_add_object_to_event_stream_group
  @stream_group_name = 'SqlCesGroup',
  @object_name = 'dbo.TableWithNoPK',
  @include_old_values = 0,
  @include_all_columns = 0
```

You can use `sp_help_change_feed_table` to inspect the current CES configuration for each table in your stream group. This will show you which tables are included, their old value settings, and other details:

```sql
EXEC sp_help_change_feed_table @source_schema = 'dbo', @source_name = 'Customer'
EXEC sp_help_change_feed_table @source_schema = 'dbo', @source_name = 'Product'
EXEC sp_help_change_feed_table @source_schema = 'dbo', @source_name = 'Order'
EXEC sp_help_change_feed_table @source_schema = 'dbo', @source_name = 'OrderDetail'
EXEC sp_help_change_feed_table @source_schema = 'dbo', @source_name = 'TableWithNoPK'
```

You can also query `sys.dm_change_feed_errors` to diagnose any issues with change event publishing:

```sql
SELECT * FROM sys.dm_change_feed_errors ORDER BY entry_time
```
