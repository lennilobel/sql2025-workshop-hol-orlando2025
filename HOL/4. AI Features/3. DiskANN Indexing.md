# DiskANN Indexing

This lab builds upon the foundational concepts introduced in the previous vector search lab, this time applying those principles to a real-world relational database using AdventureWorks2022. Our goal is to move beyond primitive examples into more scalable and realistic scenarios by using vector search to find semantically similar products based on their names and descriptions.

### Introducing DiskANN

In addition to using similar techniques as our earlier lab on vector search, this lab introduces Microsoft's proprietary **DiskANN** algorithm. This allows us to transition from **KNN (k-nearest neighbor)** search—which examines all rows when used with the `VECTOR_DISTANCE` function—to **ANN (approximate nearest neighbor)** search, which uses a precomputed vector index to achieve far better performance at scale using the `VECTOR_SEARCH` function.

The AdventureWorks2022 database contains product data, including names and descriptions. We will create a new table to store vector embeddings for these products, vectorize their text using Azure OpenAI, and then implement both KNN and ANN search procedures to find similar products based on user queries.

> **Note:** Because we are working with a relatively small database, the performance benefits of ANN will not be readily apparent. The true power of ANN indexing shines when working with extremely large datasets, where it can significantly speed up queries while maintaining high accuracy. Of course, the steps to implement DiskANN indexing are the same regardless of dataset size, and the principles learned here apply equally to larger, more complex systems than AdventureWorks2022.

Here's why DiskANN is so crucial for scalability. When vectorizing and searching across millions of items, computing distance between a query vector and every row (as KNN does) becomes expensive. ANN solves this by **pruning dissimilar vectors early**, speeding up queries while striving to **retain a recall of 1**—meaning the top results would match what you'd get with a full scan. It's called **DiskANN** because it builds and queries the index directly on disk—optimized for SSDs—so it can handle massive datasets without requiring the entire index to reside in memory.

Let's begin.

## Setup

- Connect to SQL Server using SQL Server Management Studio (SSMS).

- Press `CTRL+N` to open a new query window.

In case you skipped the previous lab, you will first need to enable SQL Server's external REST endpoint capabilities so that it can call out to Azure Open AI. If you already completed the previous lab, there is no harm in enabling REST calls once they are already enabled.

```sql
-- Enable REST API support for the system procedure sp_invoke_external_rest_endpoint
USE master
GO

EXEC sp_configure 'external rest endpoint enabled', 1
GO
RECONFIGURE WITH OVERRIDE
GO
```

Now switch to the AdventureWorks2022 database, which contains the product data we will use for vectorization and search:

```sql
USE AdventureWorks2022
GO
```

## Securely Store the Azure OpenAI API Key

We will take a similar approach to calling Azure Open AI as the previous lab, but this time we will store the sensitive Azure OpenAI API key in a database-scoped credential. This allows SQL Server to securely access the Azure OpenAI service without hardcoding (exposing) the key in our stored procedure, as we did in the previous lab.

To do this, we create a **database master key** and a **database-scoped credential** to securely store the Azure OpenAI API key. We will then be able to reference this credential when invoking the REST API endpoint in our stored procedure, without exposing the actual key.

> **Note:** A database can only have one master key, so if you have already created one in the AdventureWorks2022 database, this code will not try to create another one:

```sql
IF NOT EXISTS (SELECT * FROM sys.symmetric_keys WHERE name = '##MS_DatabaseMasterKey##')
  CREATE MASTER KEY ENCRYPTION BY PASSWORD = 'H@rd2Gue$$P@$$w0rd'

CREATE DATABASE SCOPED CREDENTIAL [https://lenni-openai.openai.azure.com] WITH
  IDENTITY = 'HTTPEndpointHeaders',
  SECRET = '{"api-key": "provided by your instructor"}'

GO
```

Note that the database-scoped credential name must match the URL of your Azure OpenAI endpoint (`https://lenni-openai.openai.azure.com`, in this case). Because the name therefore contains punctuation (like colon `:` and slash `/` characters), we must also surround it with square brackets. The `IDENTITY` value is a special value that indicates this credential is used for HTTP endpoint headers, and the `SECRET` contains the actual API key in JSON format.

## Create VectorizeText Stored Procedure

In our first lab, we used Azure OpenAI's `text-embedding-3-large` model to generate vector embeddings from text. That model returned 3072-dimensional vectors, which we needed to compress down to 1536-dimensions in order to accomodate SQL Server's current limit of 1998-dimensions.

In this lab, we will leverage the `text-embedding-ada-002` model, which returns 1536-dimensional vectors, so no compression will be needed.

The following procedure sends input text to Azure OpenAI, retrieves the embedding vector, and returns it as a `vector(1536)` value:

```sql
-- Create a procedure that will use sp_invoke_external_rest_endpoint to interface with an AI model that supports embeddings
CREATE PROCEDURE VectorizeText
  @Text varchar(max),
  @Vector vector(1536) OUTPUT
AS
BEGIN

  -- Azure OpenAI endpoint
  DECLARE @OpenAIEndpoint varchar(max) = 'https://lenni-openai.openai.azure.com/'
  DECLARE @OpenAIDeploymentName varchar(max) = 'lenni-text-embedding-ada-002' -- returns 1536-dimensional vectors
  DECLARE @OpenAIApiVersionVersion varchar(max) = '2023-05-15'
  DECLARE @Url varchar(max) = CONCAT(@OpenAIEndpoint, 'openai/deployments/', @OpenAIDeploymentName, '/embeddings?api-version=', @OpenAIApiVersionVersion)

  -- Payload includes the text to be vectorized
  DECLARE @Payload varchar(max) = JSON_OBJECT('input': @Text)

  -- Response and return value
  DECLARE @Response nvarchar(max)
  DECLARE @ReturnValue int

  -- Call Azure OpenAI to vectorize the text
  EXEC @ReturnValue = sp_invoke_external_rest_endpoint
    @url = @Url,
    @method = 'POST',
    @credential = [https://lenni-openai.openai.azure.com],
    @payload = @Payload,
    @response = @Response OUTPUT

  IF @ReturnValue != 0
    THROW 50000, @Response, 1

  DECLARE @VectorJson varchar(max) = JSON_QUERY(@Response, '$.result.data[0].embedding')

  SET @Vector = CONVERT(vector(1536), @VectorJson)

END
GO
```

Also notice how this stored procedure uses the `@credential` parameter to reference the database-scoped credential holding the API key, rather than exposing the API key in the stored procedure code as we did in the previous lab that used the `@headers` parameter to supply the API key. Internally, the `sp_invoke_external_rest_endpoint` procedure will automatically fetch the API key from the database-scoped credential, and include it in the request headers.

Now test the stored procedure to confirm that we are able to successfully vectorize text and retrieve the expected 1536-dimensional vector:

```sql
-- Test the stored procedure
DECLARE @Vector vector(1536)
EXEC VectorizeText 'Sample text to be vectorized', @Vector OUTPUT

SELECT
  Vector      = @Vector,
  Dimensions  = VECTORPROPERTY(@Vector, 'Dimensions'),
  BaseType    = VECTORPROPERTY(@Vector, 'BaseType'),
  Magnitude   = VECTOR_NORM(@Vector, 'norm2'),
  Normalized  = VECTOR_NORMALIZE(@Vector, 'norm2')

GO
```

If everything is set up correctly, you should see the first fragment of the 1536-dimensional vector generated from the sample text returned by the `Vector` column. The `Dimensions` column should show `1536`, confirming that the vector is indeed 1536-dimensional. The `BaseType` should be `float32`, the `Magnitude` should be 1 (or almost exactly 1, due to rounding errors in calculating the norm), and the `Normalized` column should show the identical value as `Vector`, since normalizing a vector that is already normalized has no effect.

## Create ProductVector Table

Now we’ll define a new table to store vector embeddings for AdventureWorks products:

```sql
CREATE TABLE Production.ProductVector (
  ProductVectorID       int IDENTITY NOT NULL,
  ProductID			    int NOT NULL,
  ProductDescriptionId  int NOT NULL,
  ProductVector         vector(1536),

  CONSTRAINT PK_ProductVector       PRIMARY KEY CLUSTERED (ProductVectorID),
  CONSTRAINT FK_Product             FOREIGN KEY (ProductID) REFERENCES Production.Product(ProductID),
  CONSTRAINT FK_ProductDescription  FOREIGN KEY (ProductDescriptionID) REFERENCES Production.ProductDescription(ProductDescriptionID),
)
GO
```

Now populate the `Production.ProductVector` table with the product IDs and their corresponding product description IDs. This will allow us to later vectorize the product names and descriptions and store them in the `ProductVector` column:

```sql
INSERT INTO Production.ProductVector (ProductID, ProductDescriptionID)
SELECT
  p.ProductID,
  pd.ProductDescriptionID
FROM
Production.Product                                             AS p
  INNER JOIN Production.ProductModel                           AS pm     ON pm.ProductModelID = p.ProductModelID
  INNER JOIN Production.ProductModelProductDescriptionCulture  AS pmpdc  ON pmpdc.ProductModelID = pm.ProductModelID
  INNER JOIN Production.ProductDescription                     AS pd     ON pd.ProductDescriptionID = pmpdc.ProductDescriptionID
WHERE
  pmpdc.CultureID = 'en'

GO
```

This creates the base table that will later hold vector representations of each product’s name and description. The `WHERE` clause is filtering for the English culture (`en`) to ensure we only include products with descriptions in English. This should result in 294 products.

> **Tip:** In fact, we could omit this filter and include products with descriptions in *all* languages. In that case, we could then pose natural language queries in *any* language, and the vector search would still work. This is a powerful feature of vector search, as it allows for multilingual queries and product descriptions without requiring translation. However, in order to limit the number of products to vectorize in this lab down to 294, we are only including English product descriptions.

Query the table to confirm it has been populated correctly:

```sql
-- Examine the product vector table not yet populated with vectors
SELECT * FROM Production.ProductVector
GO
```

You should see 294 rows, each with `ProductID` and `ProductDescriptionID` values, and a `NULL` value for the `ProductVector` column (as we have not yet populated the vectors).

## Vectorize Products

Next, we will use a cursor to construct a textual description for each product, send it to OpenAI stored procedure, and store the resulting vector to the database.

This T-SQL script iterates through a cursor of all products in the `Production.ProductVector` table, joining each with its name and description from the `Product` and `ProductDescription` tables. For each product, it concatenates the name and description into a single string, then passes that text to the `VectorizeText` stored procedure to generate a new 1536-dimensional embedding vector from Azure OpenAI. The resulting vector is then written to the corresponding row in the `ProductVector` table. A counter tracks progress, and each iteration emits a message using `RAISERROR ... WITH NOWAIT` to provide real-time feedback during execution.

```sql
SET NOCOUNT ON

DECLARE @ProductName nvarchar(max)
DECLARE @ProductDescription nvarchar(max)
DECLARE @ProductID int
DECLARE @ProductDescriptionID int

DECLARE ProductCursor CURSOR FOR
  SELECT
    p.Name,
    pd.Description,
    p.ProductID,
    pd.ProductDescriptionID
  FROM
    Production.ProductVector                  AS pv
    INNER JOIN Production.Product             AS p  ON p.ProductId = pv.ProductId
    INNER JOIN Production.ProductDescription  AS pd ON pd.ProductDescriptionID = pv.ProductDescriptionID
  ORDER BY
    p.Name

OPEN ProductCursor

  FETCH NEXT FROM ProductCursor INTO @ProductName, @ProductDescription, @ProductID, @ProductDescriptionID
  
  DECLARE @Counter int = 1
  
  WHILE @@FETCH_STATUS = 0
  BEGIN

    DECLARE @ProductText nvarchar(max) = (SELECT 'Name: ' || @ProductName || ', Description: ' || @ProductDescription)
    
    DECLARE @Message nvarchar(max) = @Counter || ' - ' || @ProductText
    RAISERROR(@Message, 0, 1) WITH NOWAIT
    
    DECLARE @ProductVector vector(1536)
    EXEC VectorizeText @ProductText, @ProductVector OUTPUT
    
    UPDATE Production.ProductVector
    SET ProductVector = @ProductVector
    WHERE ProductID = @ProductID
    
    FETCH NEXT FROM ProductCursor INTO @ProductName, @ProductDescription, @ProductID, @ProductDescriptionID
    
    SET @Counter += 1

  END

CLOSE ProductCursor
DEALLOCATE ProductCursor
SET NOCOUNT OFF

GO
```
It will take about a minute or two to vectorize all products, depending on your connection speed and the performance of the Azure OpenAI service. The cursor iterates through each product, constructs a text description combining the product name and description, and then calls the `VectorizeText` procedure to generate the vector embedding. The resulting vector is then stored in the `ProductVector` column of the `Production.ProductVector` table.

> **Tip:** Click the **Messages** tab to monitor the vectorization progress generated from the `RAISERROR` messages.

After all 294 products have been vectorized, the `Production.ProductVector` table will be fully populated with corresponding vectors. You can verify this by running the following query:

```sql
-- Examine the generated product vectors
SELECT
  p.Name,
  pd.Description,
  pv.ProductID,
  pv.ProductDescriptionID,
  pv.ProductVector,
  Dimensions  = VECTORPROPERTY(ProductVector, 'Dimensions'),
  BaseType    = VECTORPROPERTY(ProductVector, 'BaseType'),
  Magnitude   = VECTOR_NORM(ProductVector, 'norm2'),
  Normalized  = VECTOR_NORMALIZE(ProductVector, 'norm2')
FROM
  Production.ProductVector                  AS pv
  INNER JOIN Production.Product             AS p   ON p.ProductID = pv.ProductID			
  INNER JOIN Production.ProductDescription  AS pd  ON pd.ProductDescriptionID = pv.ProductDescriptionID

GO
```

Observe that the `ProductVector` column now contains 1536-dimensional vectors for each product, and the `Dimensions` column confirms that each vector has 1536 dimensions. The `BaseType` should be `float32`, the `Magnitude` should be 1 (or very close to it), and the `Normalized` column should show the same value as `ProductVector`, indicating that the vectors provided by Azure OpenAI are already normalized.

## Create SearchProductsKNN Stored Procedure

This stored procedure performs a **KNN (exact)** search by comparing the query vector to every row using `VECTOR_DISTANCE()`. This is exactly how we ran our vector search in the first lab:

```sql
-- Execute a hybrid KNN (exact) vector search using VECTOR_DISTANCE() combined with traditional search
CREATE PROCEDURE SearchProductsKNN
  @QueryText      nvarchar(max),
  @MinStockLevel  smallint         = 100,
  @MaxDistance    decimal(19, 16)  = 0.2,
  @Top            int              = 20
AS
BEGIN

  DECLARE @QueryVector vector(1536)
  EXEC VectorizeText @QueryText, @QueryVector OUTPUT
  
  ;WITH ProductVectorCte AS (
    SELECT TOP (@Top)
      ProductID,
      ProductDescriptionID,
      Distance = VECTOR_DISTANCE('cosine', ProductVector, @QueryVector)
    FROM
      Production.ProductVector
    ORDER BY
      Distance
  )
  SELECT
    ProductName         = p.Name,
    ProductDescription  = pd.Description,
    p.SafetyStockLevel,
    pv.Distance
  FROM
    ProductVectorCte                          AS pv
    INNER JOIN Production.Product             AS p   ON p.ProductID = pv.ProductID
    INNER JOIN Production.ProductDescription  AS pd  ON pd.ProductDescriptionID = pv.ProductDescriptionID
  WHERE
    pv.Distance < @MaxDistance AND
    p.SafetyStockLevel >= @MinStockLevel
  ORDER BY    
    pv.Distance

END
GO
```

This stored procedure performs a "hybrid" vector-based product search. It accepts a free-text query and calls `VectorizeText` to convert that query into a 1536-dimensional embedding vector. The procedure then compares this vector to precomputed product vectors stored in the `Production.ProductVector` table using the `VECTOR_DISTANCE` function with cosine similarity (just as we did with the `Movies` database in our first lab). It selects the top N closest matches (as specified by the `@Top` parameter) and filters out any that exceed a maximum distance threshold (`@MaxDistance`). It also enforces a minimum safety stock level (`@MinStockLevel`) to exclude products with insufficient inventory.

The advantage of this hybrid approach is that it blends the power of semantic search with practical business constraints. Instead of simply returning the most semantically similar items—which might include unavailable or irrelevant products—it ensures that only in-stock and relevant items are shown to users. This makes the procedure ideal for intelligent product discovery, personalized recommendations, or enhanced search experiences where both meaning and availability matter.

## Test the SearchProductsKNN Stored Procedure

Now let's test the `SearchProductsKNN` stored procedure to see how it performs semantic search on our product data:

```sql
EXEC SearchProductsKNN 'Show me the best products for riding on rough ground'
```

Top results should include mountain bikes, off-road tires, and other products suitable for rough terrain. The results will be ordered by their semantic similarity to the query, with the closest matches appearing first.

```sql
EXEC SearchProductsKNN 'Recommend a bike that is good for riding around the city'
```

This query returns touring bikes, city bikes, and other products suitable for urban riding. The results are again ordered by semantic similarity.

```sql
EXEC SearchProductsKNN 'Looking for budget-friendly gear for beginners just getting into cycling'
```

Now you'll get results that include entry-level bikes, affordable helmets, and other beginner-friendly products. The results are tailored to the user's budget and experience level.

```sql
EXEC SearchProductsKNN 'What''s best for long-distance rides with storage for travel gear?'
```

These results should include touring bikes, bikes with racks, and other products designed for long-distance travel. The search understands the need for storage and comfort on long rides.

```sql
EXEC SearchProductsKNN 'Do you have any yellow or red bikes?'
```

Now you'll see results that include bikes with yellow or red colors, demonstrating the search's ability to understand color preferences.

```sql
EXEC SearchProductsKNN 'Do you have any yellow or red apples?'
```

This query returns no results at all, as there are no products in the AdventureWorks2022 database that match this description. This demonstrates how the search can handle queries that do not match any existing products, returning an empty result set rather than irrelevant results. We are, after all, selling bikes, not apples.

However, if you try the same query with a higher `@MaxDistance` value, you may get some results that are not exactly apples but are semantically similar products:

```sql
EXEC SearchProductsKNN 'Do you have any yellow or red apples?', @MaxDistance = 0.3
```

And now we do get some results, such as yellow or red bikes, not apples. This shows how adjusting the `@MaxDistance` parameter can narrow the search results to include only more tightly related items.

## Create a DiskANN Vector Index

Until now, we have been using a **KNN search**—accurate but potentially slow on large datasets.

If we need to scale this to millions of products, we can use **ANN (approximate nearest neighbor)** search with a **DiskANN** index. This allows us to perform fast vector searches without needing to compute distances for every single row, which is what KNN does.

Let's create a **DiskANN** index to enable fast ANN queries over the `ProductVector` column of the `Production.ProductVector` table. But first, we need to enable the necessary trace flags for DiskANN indexing, as it is still in preview in SQL Server 2025:

```sql
-- Enable the necessary trace flags for DiskANN indexing while the feature is still in preview
DBCC TRACEON(466, 474, 13981, -1)
```

Now create the index:
 
 ```sql
CREATE VECTOR INDEX ProductVectorDiskANNIndex
  ON Production.ProductVector (ProductVector)
  WITH (
    METRIC = 'cosine',
    TYPE = 'diskann',
    MAXDOP = 8
)
GO
```

You have now created a DiskANN index on the `ProductVector` column of the `Production.ProductVector` table. This index will allow for fast approximate nearest neighbor (ANN) searches using the `VECTOR_SEARCH()` function, which we will implement in the next section.

Note the Metric is set to `cosine`, which is the same metric we used for the KNN search. The `TYPE` is set to `diskann`, indicating that this is a DiskANN index. The `MAXDOP` option specifies the maximum degree of parallelism for index operations, which can help improve performance on multi-core systems.

> **More Info on MAXDOP:**
>
> The `MAXDOP` setting controls how many CPU threads SQL Server can use when building (or rebuilding) the index. You might increase `MAXDOP` (for example, to 16 or 32) on a dedicated machine with many idle cores if you need the index build to finish as quickly as possible—especially when the table contains millions of vectors and you’re willing to use more CPU to speed up that one-time operation. Conversely, you’d lower `MAXDOP` (for example, to 1 or 2) on a busy or smaller server to prevent the index build from monopolizing CPU resources needed by other queries. In other words:
> * **High `MAXDOP`** (e.g., equal to or slightly less than your physical core count) = fastest build time, but risk of CPU contention if other workloads are running.
>* **Low `MAXDOP`** (e.g., 1 or 2) = slower build, but leaves more cores free for other processes, which is ideal on a multi‐tenant or production system under constant load.
> 
> Choosing the right value depends on your hardware (number of cores, available memory) and your workload priorities (faster index build vs. overall system responsiveness). For this lab, our dataset is so small that it almost makes no difference what value is used, but in a real-world scenario, you would adjust `MAXDOP` based on your specific environment and performance needs.

Now query the `sys.indexes` system view to confirm that the index has been created successfully:

```sql
SELECT * FROM sys.indexes WHERE name = 'ProductVectorDiskANNIndex'
```

Note that the `type_desc` column shows `VECTOR`, indicating that this is a DiskANN vector index. Again, this index is based on an *approximate* nearest neighbor algorightm, which works very differently than the traditional B-tree structures of conventional table indexes in SQL Server.

> **Important:** In its current implementation, once you create a **DiskANN index**, the table becomes **read-only**. To modify data, you must drop and recreate the index. This limitation is expected to be lifted in a future release of SQL Server.

Creating the index speeds up ANN queries—but also locks the table from modification. To demonstrate this, try updating a row into the `Production.ProductVector` table after creating the index:

```sql
UPDATE Production.ProductVector SET ProductVector = NULL
```

This will fail with an error message indicating that the table is read-only due to the DiskANN index. This is a known limitation of the current implementation of DiskANN indexing in SQL Server.

## Create SearchProductsANN Stored Procedure

Now we can create a new stored procedure that uses the DiskANN index to perform fast approximate nearest neighbor (ANN) searches. This stored procedure uses the new `VECTOR_SEARCH()` function to perform **ANN (approximate)** search using the DiskANN index:

```sql
-- Execute a hybrid ANN (approximate) vector search using VECTOR_SEARCH() combined with traditional search
CREATE PROCEDURE SearchProductsANN
  @QueryText      nvarchar(max),
  @MinStockLevel  smallint         = 100,
  @MaxDistance    decimal(19, 16)  = 0.2,
  @Top            int              = 20
AS
BEGIN

  DECLARE @QueryVector vector(1536)
  EXEC VectorizeText @QueryText, @QueryVector OUTPUT

  SELECT
    ProductName			= p.Name,
    ProductDescription	= pd.Description,
    p.SafetyStockLevel,
    pvs.Distance
  FROM
    VECTOR_SEARCH(
      TABLE       = Production.ProductVector    AS pvt,
      COLUMN      = ProductVector,
      SIMILAR_TO  = @QueryVector,
      METRIC      = 'cosine',
      TOP_N       = @top
    )                                           AS pvs
    INNER JOIN Production.ProductVector         AS pv   ON pvt.ProductVectorID = pv.ProductVectorID
    INNER JOIN Production.Product               AS p    ON pv.ProductID = p.ProductID
    INNER JOIN Production.ProductDescription    AS pd   ON pd.ProductDescriptionID = pv.ProductDescriptionID
  WHERE
    pvs.Distance < @MaxDistance AND
    p.SafetyStockLevel >= @MinStockLevel
  ORDER BY
    pvs.distance

END
GO
```

Run the same queries as before, but this time using the `SearchProductsANN` stored procedure:
```sql
EXEC SearchProductsANN 'Show me the best products for riding on rough ground'
EXEC SearchProductsANN 'Recommend a bike that is good for riding around the city'
EXEC SearchProductsANN 'Looking for budget-friendly gear for beginners just getting into cycling'
EXEC SearchProductsANN 'What''s best for long-distance rides with storage for travel gear?'
EXEC SearchProductsANN 'Do you have any yellow or red bikes?'
EXEC SearchProductsANN 'Do you have any yellow or red apples?'
EXEC SearchProductsANN 'Do you have any yellow or red apples?', @MaxDistance = 0.3
```

The results should be identical to those returned by the `SearchProductsKNN` stored procedure, indicating an ideal recall of 1 (meaning that the approximate search algorithm on the DiskANN index has matched every vector that the exact KNN search algorithm did). However, the ANN search will be much faster than the KNN search, as the dataset grows larger.

### KNN vs. ANN in SQL Server

* `VECTOR_DISTANCE` (used in KNN search) computes the distance between a query vector and every row. This guarantees **exact** results, but becomes **slow** at scale.
* `VECTOR_SEARCH` (used in ANN search with DiskANN) builds an **approximate** index. It returns top matches **much faster**, especially over millions of rows, while still striving to retain **recall = 1**, meaning the top results would match what a full scan would yield.

In this lab, the dataset is too small to measure real performance gains. But on large datasets, the benefits of ANN become clear.

**Congratulations! You’ve now learned how to:**

* Store embeddings using real-world product data
* Perform both KNN and ANN vector search
* Use the new DiskANN vector index to enable blazing-fast approximate search at massive scale

___

▶ [Lab: External AI Models](https://github.com/lennilobel/sql2025-workshop-hol-orlando2025/blob/main/HOL/4.%20AI%20Features/4.%20External%20AI%20Models.md)
